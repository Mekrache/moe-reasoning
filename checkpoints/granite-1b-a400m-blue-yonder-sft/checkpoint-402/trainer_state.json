{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 402,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04975124378109453,
      "grad_norm": 1.035079836845398,
      "learning_rate": 0.0002925373134328358,
      "loss": 0.7109,
      "step": 10
    },
    {
      "epoch": 0.09950248756218906,
      "grad_norm": 0.6403712034225464,
      "learning_rate": 0.00028507462686567164,
      "loss": 0.4129,
      "step": 20
    },
    {
      "epoch": 0.14925373134328357,
      "grad_norm": 0.4840426445007324,
      "learning_rate": 0.00027761194029850744,
      "loss": 0.3734,
      "step": 30
    },
    {
      "epoch": 0.19900497512437812,
      "grad_norm": 0.41329678893089294,
      "learning_rate": 0.00027014925373134325,
      "loss": 0.3529,
      "step": 40
    },
    {
      "epoch": 0.24875621890547264,
      "grad_norm": 0.4086892306804657,
      "learning_rate": 0.0002626865671641791,
      "loss": 0.3513,
      "step": 50
    },
    {
      "epoch": 0.29850746268656714,
      "grad_norm": 0.33355259895324707,
      "learning_rate": 0.0002552238805970149,
      "loss": 0.3497,
      "step": 60
    },
    {
      "epoch": 0.3482587064676617,
      "grad_norm": 0.37363749742507935,
      "learning_rate": 0.0002477611940298507,
      "loss": 0.354,
      "step": 70
    },
    {
      "epoch": 0.39800995024875624,
      "grad_norm": 0.4062064290046692,
      "learning_rate": 0.00024029850746268655,
      "loss": 0.3362,
      "step": 80
    },
    {
      "epoch": 0.44776119402985076,
      "grad_norm": 0.3924499750137329,
      "learning_rate": 0.00023283582089552238,
      "loss": 0.3497,
      "step": 90
    },
    {
      "epoch": 0.4975124378109453,
      "grad_norm": 0.40436941385269165,
      "learning_rate": 0.0002253731343283582,
      "loss": 0.353,
      "step": 100
    },
    {
      "epoch": 0.5472636815920398,
      "grad_norm": 0.30514174699783325,
      "learning_rate": 0.00021791044776119401,
      "loss": 0.3522,
      "step": 110
    },
    {
      "epoch": 0.5970149253731343,
      "grad_norm": 0.30135321617126465,
      "learning_rate": 0.00021044776119402985,
      "loss": 0.3383,
      "step": 120
    },
    {
      "epoch": 0.6467661691542289,
      "grad_norm": 0.32956328988075256,
      "learning_rate": 0.00020298507462686565,
      "loss": 0.3508,
      "step": 130
    },
    {
      "epoch": 0.6965174129353234,
      "grad_norm": 0.34364667534828186,
      "learning_rate": 0.00019552238805970148,
      "loss": 0.343,
      "step": 140
    },
    {
      "epoch": 0.746268656716418,
      "grad_norm": 0.3197751045227051,
      "learning_rate": 0.0001880597014925373,
      "loss": 0.3517,
      "step": 150
    },
    {
      "epoch": 0.7960199004975125,
      "grad_norm": 0.39612674713134766,
      "learning_rate": 0.00018059701492537312,
      "loss": 0.3387,
      "step": 160
    },
    {
      "epoch": 0.845771144278607,
      "grad_norm": 0.3085726201534271,
      "learning_rate": 0.00017313432835820895,
      "loss": 0.353,
      "step": 170
    },
    {
      "epoch": 0.8955223880597015,
      "grad_norm": 0.3239751160144806,
      "learning_rate": 0.00016567164179104478,
      "loss": 0.3301,
      "step": 180
    },
    {
      "epoch": 0.945273631840796,
      "grad_norm": 0.3289651870727539,
      "learning_rate": 0.00015820895522388059,
      "loss": 0.3428,
      "step": 190
    },
    {
      "epoch": 0.9950248756218906,
      "grad_norm": 0.296853244304657,
      "learning_rate": 0.00015074626865671642,
      "loss": 0.3406,
      "step": 200
    },
    {
      "epoch": 1.044776119402985,
      "grad_norm": 0.2644903361797333,
      "learning_rate": 0.00014328358208955222,
      "loss": 0.3318,
      "step": 210
    },
    {
      "epoch": 1.0945273631840795,
      "grad_norm": 0.2784308195114136,
      "learning_rate": 0.00013582089552238805,
      "loss": 0.3182,
      "step": 220
    },
    {
      "epoch": 1.144278606965174,
      "grad_norm": 0.2843764126300812,
      "learning_rate": 0.00012835820895522386,
      "loss": 0.3246,
      "step": 230
    },
    {
      "epoch": 1.1940298507462686,
      "grad_norm": 0.2778542935848236,
      "learning_rate": 0.00012089552238805969,
      "loss": 0.3148,
      "step": 240
    },
    {
      "epoch": 1.243781094527363,
      "grad_norm": 0.3283468186855316,
      "learning_rate": 0.00011343283582089551,
      "loss": 0.3217,
      "step": 250
    },
    {
      "epoch": 1.2935323383084576,
      "grad_norm": 0.2617586851119995,
      "learning_rate": 0.00010597014925373134,
      "loss": 0.3167,
      "step": 260
    },
    {
      "epoch": 1.3432835820895521,
      "grad_norm": 0.31162452697753906,
      "learning_rate": 9.850746268656716e-05,
      "loss": 0.3257,
      "step": 270
    },
    {
      "epoch": 1.3930348258706466,
      "grad_norm": 0.2679327428340912,
      "learning_rate": 9.104477611940298e-05,
      "loss": 0.3124,
      "step": 280
    },
    {
      "epoch": 1.4427860696517412,
      "grad_norm": 0.283984899520874,
      "learning_rate": 8.358208955223881e-05,
      "loss": 0.3179,
      "step": 290
    },
    {
      "epoch": 1.4925373134328357,
      "grad_norm": 0.27943477034568787,
      "learning_rate": 7.611940298507463e-05,
      "loss": 0.3263,
      "step": 300
    },
    {
      "epoch": 1.5422885572139302,
      "grad_norm": 0.37305763363838196,
      "learning_rate": 6.865671641791044e-05,
      "loss": 0.3231,
      "step": 310
    },
    {
      "epoch": 1.5920398009950247,
      "grad_norm": 0.2774263620376587,
      "learning_rate": 6.119402985074626e-05,
      "loss": 0.3145,
      "step": 320
    },
    {
      "epoch": 1.6417910447761193,
      "grad_norm": 0.307222843170166,
      "learning_rate": 5.373134328358208e-05,
      "loss": 0.3199,
      "step": 330
    },
    {
      "epoch": 1.6915422885572138,
      "grad_norm": 0.2803308367729187,
      "learning_rate": 4.6268656716417905e-05,
      "loss": 0.3074,
      "step": 340
    },
    {
      "epoch": 1.7412935323383083,
      "grad_norm": 0.33257365226745605,
      "learning_rate": 3.880597014925372e-05,
      "loss": 0.3227,
      "step": 350
    },
    {
      "epoch": 1.7910447761194028,
      "grad_norm": 0.27457165718078613,
      "learning_rate": 3.134328358208955e-05,
      "loss": 0.3234,
      "step": 360
    },
    {
      "epoch": 1.8407960199004973,
      "grad_norm": 0.31585708260536194,
      "learning_rate": 2.388059701492537e-05,
      "loss": 0.3177,
      "step": 370
    },
    {
      "epoch": 1.890547263681592,
      "grad_norm": 0.26294779777526855,
      "learning_rate": 1.6417910447761194e-05,
      "loss": 0.3372,
      "step": 380
    },
    {
      "epoch": 1.9402985074626866,
      "grad_norm": 0.27791598439216614,
      "learning_rate": 8.955223880597014e-06,
      "loss": 0.3153,
      "step": 390
    },
    {
      "epoch": 1.9900497512437811,
      "grad_norm": 0.26774945855140686,
      "learning_rate": 1.4925373134328356e-06,
      "loss": 0.3179,
      "step": 400
    }
  ],
  "logging_steps": 10,
  "max_steps": 402,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.8514847100502016e+16,
  "train_batch_size": 9,
  "trial_name": null,
  "trial_params": null
}
